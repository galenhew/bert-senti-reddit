{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"00Fkv8gvR8Mi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502208832,"user_tz":-480,"elapsed":10638,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"edf01b95-f39f-478d-df9d-579d9e02aefb"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install shap\n","!pip install ffn\n","!pip install --upgrade pandas-datareader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poL0nMjkSodH","executionInfo":{"status":"ok","timestamp":1668502228739,"user_tz":-480,"elapsed":19914,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"46b2e07e-2b4f-47cc-e404-4cac0a25550d"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.41.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.56.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.5.0)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.1)\n","Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.7.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->shap) (4.13.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.39.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (3.10.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ffn in /usr/local/lib/python3.7/dist-packages (0.3.6)\n","Requirement already satisfied: future>=0.15 in /usr/local/lib/python3.7/dist-packages (from ffn) (0.16.0)\n","Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.7/dist-packages (from ffn) (1.0.2)\n","Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.7/dist-packages (from ffn) (1.7.3)\n","Requirement already satisfied: numpy>=1.5 in /usr/local/lib/python3.7/dist-packages (from ffn) (1.21.6)\n","Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from ffn) (0.10.0)\n","Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from ffn) (0.8.10)\n","Requirement already satisfied: matplotlib>=1 in /usr/local/lib/python3.7/dist-packages (from ffn) (3.2.2)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from ffn) (1.3.5)\n","Requirement already satisfied: decorator>=4 in /usr/local/lib/python3.7/dist-packages (from ffn) (4.4.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1->ffn) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1->ffn) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1->ffn) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1->ffn) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1->ffn) (4.1.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->ffn) (2022.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->ffn) (4.9.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->ffn) (2.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1->ffn) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn) (2.10)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.15->ffn) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.15->ffn) (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.9.1)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.23.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2022.9.24)\n"]}]},{"cell_type":"code","execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":58}],"source":["# Python libraries\n","# Data Science modules\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.style.use('ggplot')\n","from collections import defaultdict\n","from textwrap import wrap\n","import pickle\n","import shap\n","import ffn\n","from tqdm import tqdm\n","\n","# Import nltk modules and download dataset\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.util import ngrams\n","from nltk.tokenize import word_tokenize\n","import statistics\n","\n","# Import Scikit-learn moduels\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import model_selection\n","from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, StratifiedKFold, learning_curve, RandomizedSearchCV\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.preprocessing import MinMaxScaler\n","# import scikit-plot as skplt\n","\n","\n","# huggingface and torch\n","from torch import nn, optim\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","import tqdm\n","\n","stop = set(stopwords.words('english'))\n","\n","RANDOM_SEED = 42\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"K5Ph7aqVRrI_","outputId":"8a843622-2217-46b4-fe2a-bce3f449e813","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502228739,"user_tz":-480,"elapsed":14,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","source":["colab_path= \"/content/drive/Othercomputers/My MacBook Pro/data-science/Georgia Tech/MGT6203- Data Analytics Business/MGT6203 Project/\"\n","finphrase_dir = \"data/FinancialPhraseBank/\"\n","filename = 'Sentences_50Agree.txt'\n","model_path= colab_path + \"draft/best_model_state.bin\""],"metadata":{"id":"KCGDdsV4RuQH","executionInfo":{"status":"ok","timestamp":1668502228740,"user_tz":-480,"elapsed":11,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","execution_count":60,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"BL47S2wTRrJD","executionInfo":{"status":"ok","timestamp":1668502228740,"user_tz":-480,"elapsed":11,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"outputs":[],"source":["\n","def load_finphrase(filename):\n","    ''' Clean FinancialPhrasebank data\n","        Input:\n","            - filename\n","        Output:\n","            - a dataframe for the loaded financial phase bank data\n","    '''\n","    df = pd.read_csv(colab_path+ finphrase_dir + filename,\n","                     sep='\\@',\n","                     engine='python',\n","                     header=None,\n","                     names=['sentence','label'],\n","                     encoding='latin-1')\n","    print('Total number of record in the file: ', df.shape[0])\n","    df.drop_duplicates(inplace=True)\n","    print('Total number of record after dropping duplicates: ', df.shape[0])\n","    print('Missing label: ', df['label'].isnull().sum())\n","    df.reset_index(inplace=True, drop=True)\n","    # df = pd.get_dummies(df, columns=['label'])\n","    return df"]},{"cell_type":"code","execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of record in the file:  4846\n","Total number of record after dropping duplicates:  4840\n","Missing label:  0\n"]},{"output_type":"stream","name":"stderr","text":["Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                                                                                                                      sentence  \\\n","3200  The company serves customers in various industries , including process and resources , industrial machinery , architecture , building , construction , electrical , transportation , electronics , chemical , petrochemical , energy , and information technology , as well as catering and households .   \n","2527  Officials did not disclose the contract value .                                                                                                                                                                                                                                                            \n","4101  The extracted filtrates are very high in clarity while the dried filter cakes meet required transport moisture limits (TMLs)for their ore grades .                                                                                                                                                         \n","1926  The tool is a patent pending design that allows consumers to lay out their entire project on a removable plate using multiple clear stamps of any kind .                                                                                                                                                   \n","1536  In Finland , the corresponding service is Alma Media 's Etuovi.com , Finland 's most popular and best known nationwide online service for home and property sales .                                                                                                                                        \n","1330  Sanoma also has an Executive Committee , in accordance with the Company 's Articles of Association , that prepares proposals for matters to be decided or noted by the Board of Directors .                                                                                                                \n","2373  Finnish property investment company Citycon plans to issue directed subordinated convertible bonds to institutional investors .                                                                                                                                                                            \n","4251  The gross area of the Innova 2 project will be about 10,000 sq m ( 107,600 sq ft ) .                                                                                                                                                                                                                       \n","\n","        label  \n","3200  neutral  \n","2527  neutral  \n","4101  neutral  \n","1926  neutral  \n","1536  neutral  \n","1330  neutral  \n","2373  neutral  \n","4251  neutral  "],"text/html":["\n","  <div id=\"df-7701fd05-643e-4cba-bc0b-5b10f731d8ee\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3200</th>\n","      <td>The company serves customers in various industries , including process and resources , industrial machinery , architecture , building , construction , electrical , transportation , electronics , chemical , petrochemical , energy , and information technology , as well as catering and households .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2527</th>\n","      <td>Officials did not disclose the contract value .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4101</th>\n","      <td>The extracted filtrates are very high in clarity while the dried filter cakes meet required transport moisture limits (TMLs)for their ore grades .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1926</th>\n","      <td>The tool is a patent pending design that allows consumers to lay out their entire project on a removable plate using multiple clear stamps of any kind .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1536</th>\n","      <td>In Finland , the corresponding service is Alma Media 's Etuovi.com , Finland 's most popular and best known nationwide online service for home and property sales .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1330</th>\n","      <td>Sanoma also has an Executive Committee , in accordance with the Company 's Articles of Association , that prepares proposals for matters to be decided or noted by the Board of Directors .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2373</th>\n","      <td>Finnish property investment company Citycon plans to issue directed subordinated convertible bonds to institutional investors .</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4251</th>\n","      <td>The gross area of the Innova 2 project will be about 10,000 sq m ( 107,600 sq ft ) .</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7701fd05-643e-4cba-bc0b-5b10f731d8ee')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7701fd05-643e-4cba-bc0b-5b10f731d8ee button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7701fd05-643e-4cba-bc0b-5b10f731d8ee');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":61}],"source":["df = load_finphrase(filename)\n","\n","# Samples\n","pd.set_option('display.max_colwidth', -1)\n","df.sample(n=8, random_state=42)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"MZg0GgJTRrJE","outputId":"dd8ea1e1-57dc-42b0-abbf-4597e4c7d0fd","colab":{"base_uri":"https://localhost:8080/","height":555},"executionInfo":{"status":"ok","timestamp":1668502229340,"user_tz":-480,"elapsed":611,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["['negative', 'neutral', 'positive']\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                                               sentence  \\\n","0  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .                                                                                                        \n","1  Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .                                         \n","2  The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .   \n","3  With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .                         \n","4  According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .                            \n","\n","   label  \n","0  1      \n","1  1      \n","2  0      \n","3  2      \n","4  2      "],"text/html":["\n","  <div id=\"df-65067a15-271f-4f5a-a46e-c474b3e03521\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65067a15-271f-4f5a-a46e-c474b3e03521')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-65067a15-271f-4f5a-a46e-c474b3e03521 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-65067a15-271f-4f5a-a46e-c474b3e03521');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":62}],"source":["class_names = ['negative', 'neutral', 'positive']\n","\n","# Encode the label\n","le = LabelEncoder()\n","le.fit(df['label'])\n","print(list(le.classes_))\n","df['label'] = le.transform(df['label'])\n","# list(le.inverse_transform(df['label']))\n","df.head()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"qC2GLT1zRrJE","outputId":"f72849c7-d8dd-471e-d7c9-a2c5d79d4198","colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"status":"ok","timestamp":1668502229341,"user_tz":-480,"elapsed":7,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","source":["\n","ax = sns.countplot(df.label)\n","plt.xlabel('review sentiment')\n","ax.set_xticklabels(class_names);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVHHgWABk4-_","executionInfo":{"status":"ok","timestamp":1668502229341,"user_tz":-480,"elapsed":5,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"b40cfd17-9c68-49b6-9e3b-3e94ff38aeaa"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stderr","text":["Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n"]}]},{"cell_type":"code","execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":[" Sentence: When was I last outside? I am stuck at home for 2 weeks.\n","   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n","Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"]}],"source":["# Data Preprocessing\n","\n","PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n","tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n","tokens = tokenizer.tokenize(sample_txt)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(f' Sentence: {sample_txt}')\n","print(f'   Tokens: {tokens}')\n","print(f'Token IDs: {token_ids}')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"WSSiRyKFRrJF","outputId":"c79bd0bc-8313-4df0-ac1b-8bc7b396f3c4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502230559,"user_tz":-480,"elapsed":1223,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":65}],"source":["encoding = tokenizer.encode_plus(\n","  sample_txt,\n","  truncation=True,\n","  max_length=32,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=False,\n","  padding=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',  # Return PyTorch tensors\n",")\n","\n","encoding.keys()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ooBEaOpaRrJF","outputId":"52f67717-2747-439f-ae72-1a542613ded7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502230559,"user_tz":-480,"elapsed":12,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["17\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n","        1111,  123, 2277,  119,  102])"]},"metadata":{},"execution_count":66}],"source":["print(len(encoding['input_ids'][0]))\n","encoding['input_ids'][0]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IjqQqk_VRrJG","outputId":"2433c5c5-f930-4f2f-8bc0-c2ed2a97f0e2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502230559,"user_tz":-480,"elapsed":9,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["17\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"]},"metadata":{},"execution_count":67}],"source":["print(len(encoding['attention_mask'][0]))\n","encoding['attention_mask']"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"yQI4RxO2RrJG","outputId":"9b12ba03-24b7-4bbf-d9f9-b3d2cefa11ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502230560,"user_tz":-480,"elapsed":8,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," 'When',\n"," 'was',\n"," 'I',\n"," 'last',\n"," 'outside',\n"," '?',\n"," 'I',\n"," 'am',\n"," 'stuck',\n"," 'at',\n"," 'home',\n"," 'for',\n"," '2',\n"," 'weeks',\n"," '.',\n"," '[SEP]']"]},"metadata":{},"execution_count":68}],"source":["tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IKV-Yk0ARrJH","outputId":"22da6879-e1e4-469c-f3c0-6339d789567d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502230560,"user_tz":-480,"elapsed":6,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":69,"outputs":[{"output_type":"stream","name":"stderr","text":["`distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n"]}],"source":["# Choosing Sequence Length\n","\n","token_lens = []\n","\n","for txt in df['sentence']:\n","  tokens = tokenizer.encode(txt, truncation=True, max_length=512)\n","  token_lens.append(len(tokens))\n","\n","sns.distplot(token_lens)\n","plt.xlim([0, 256])\n","plt.xlabel('Token count')\n","\n","MAX_LEN = 160\n","\n","# mostly below 90 token count"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"dZvCuvoDRrJH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502233726,"user_tz":-480,"elapsed":3171,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"285ae002-72e8-4252-f4d2-ea5317bbe07e"}},{"cell_type":"code","execution_count":70,"outputs":[],"source":["class GPReviewDataset(Dataset):\n","\n","  def __init__(self, reviews, targets, tokenizer, max_len):\n","    self.reviews = reviews\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","\n","  def __len__(self):\n","    return len(self.reviews)\n","\n","  def __getitem__(self, item):\n","    review = str(self.reviews[item])\n","    target = self.targets[item]\n","\n","    encoding = self.tokenizer.encode_plus(\n","      review,\n","      add_special_tokens=True,\n","      max_length=self.max_len,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt',\n","    )\n","\n","    return {\n","      'review_text': review,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'targets': torch.tensor(target, dtype=torch.long)\n","    }\n","\n","\n","def create_data_loader(df, tokenizer, max_len, batch_size):\n","  ds = GPReviewDataset(\n","    reviews=df['sentence'].to_numpy(),\n","    targets=df['label'].to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4\n","  )"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"yhMVpBDNRrJH","executionInfo":{"status":"ok","timestamp":1668502233726,"user_tz":-480,"elapsed":9,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4356, 2), (242, 2), (242, 2))"]},"metadata":{},"execution_count":71}],"source":["df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n","df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n","df_train.shape, df_val.shape, df_test.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FRRsJq9vRrJI","outputId":"7903e5ae-e906-42ba-bcc6-8ec42d19f2f6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502233726,"user_tz":-480,"elapsed":9,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":72,"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]}],"source":["BATCH_SIZE = 16\n","\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"mefR6j3rRrJI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502233727,"user_tz":-480,"elapsed":8,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"fa7b39e5-784a-4188-f174-0f301bf0b7aa"}},{"cell_type":"code","execution_count":73,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"]},"metadata":{},"execution_count":73}],"source":["data = next(iter(train_data_loader))\n","data.keys()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VZgHBvG9RrJI","outputId":"b150c784-31a1-4f5f-a55a-4afa939dd508","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502234494,"user_tz":-480,"elapsed":773,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}}},{"cell_type":"code","execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 160])\n","torch.Size([16, 160])\n","torch.Size([16])\n"]}],"source":["print(data['input_ids'].shape)\n","print(data['attention_mask'].shape)\n","print(data['targets'].shape)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"DMy2rTj-RrJJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502234495,"user_tz":-480,"elapsed":3,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"015a6135-d4cc-4290-ad7a-502405f60f49"}},{"cell_type":"markdown","source":["### model"],"metadata":{"id":"PiMLYDhQRrJJ"}},{"cell_type":"code","source":["bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjJOiiPPTe6A","executionInfo":{"status":"ok","timestamp":1668502237593,"user_tz":-480,"elapsed":3100,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"5a3a310f-8b19-4665-a79a-3070008f03ce"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["last_hidden_state, pooled_output = bert_model(\n","  input_ids=encoding['input_ids'], \n","  attention_mask=encoding['attention_mask']\n",")\n","\n","last_hidden_state.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yj_k11UaTJLW","executionInfo":{"status":"ok","timestamp":1668502237593,"user_tz":-480,"elapsed":7,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"51273291-c9a2-4b62-a928-ab62e9a86515"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 17, 768])"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["bert_model.config.hidden_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnVg4kWQTP8s","executionInfo":{"status":"ok","timestamp":1668502237593,"user_tz":-480,"elapsed":4,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"92702c11-79a2-452c-907b-7d54bc1791e4"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["pooled_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpKSBeVVTQ9w","executionInfo":{"status":"ok","timestamp":1668502237593,"user_tz":-480,"elapsed":3,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"b3cf17b0-117b-45b6-c8cf-022f1ac4e9f1"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 768])"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["class SentimentClassifier(nn.Module):\n","\n","  def __init__(self, n_classes):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    _, pooled_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"metadata":{"id":"k2N9Bbx2TSY5","executionInfo":{"status":"ok","timestamp":1668502237593,"user_tz":-480,"elapsed":2,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["# define model\n","\n","model = SentimentClassifier(len(class_names))\n","model = model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7fKi9B6TTmj","executionInfo":{"status":"ok","timestamp":1668502239689,"user_tz":-480,"elapsed":2098,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"5deaf345-ec29-4be4-8ff9-f0a96c0890a1"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["input_ids = data['input_ids'].to(device)\n","attention_mask = data['attention_mask'].to(device)\n","\n","print(input_ids.shape) # batch size x seq length\n","print(attention_mask.shape) # batch size x seq length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4doL6mJ9TUmM","executionInfo":{"status":"ok","timestamp":1668502239690,"user_tz":-480,"elapsed":13,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"34f02dc8-0c59-4b23-bbb4-c165fdab0c68"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 160])\n","torch.Size([16, 160])\n"]}]},{"cell_type":"code","source":["F.softmax(model(input_ids, attention_mask), dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-__AJSs6TVj3","executionInfo":{"status":"ok","timestamp":1668502255372,"user_tz":-480,"elapsed":15685,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"4d3a947c-329e-4af9-fcd9-56ccab4f0ebe"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.6768, 0.2098, 0.1134],\n","        [0.7076, 0.1513, 0.1411],\n","        [0.7773, 0.1389, 0.0838],\n","        [0.6971, 0.1264, 0.1765],\n","        [0.2880, 0.4047, 0.3073],\n","        [0.6868, 0.1414, 0.1718],\n","        [0.7702, 0.1133, 0.1165],\n","        [0.5850, 0.2757, 0.1392],\n","        [0.6484, 0.2108, 0.1408],\n","        [0.6559, 0.1315, 0.2126],\n","        [0.7780, 0.1315, 0.0905],\n","        [0.8123, 0.0972, 0.0905],\n","        [0.5669, 0.2983, 0.1348],\n","        [0.6935, 0.1539, 0.1526],\n","        [0.5161, 0.1218, 0.3621],\n","        [0.7268, 0.1823, 0.0909]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["### train\n","- comment out after save model"],"metadata":{"id":"E53P-_T1UgMo"}},{"cell_type":"code","source":["#%%\n","EPOCHS = 10\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2gAKBAxXDlu","executionInfo":{"status":"ok","timestamp":1668502255372,"user_tz":-480,"elapsed":6,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"03bc4f30-1756-4de5-cd91-38ed760fc02f"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stderr","text":["This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n"]}]},{"cell_type":"code","source":["def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for d in data_loader:\n","    input_ids = d[\"input_ids\"].to(device)\n","    attention_mask = d[\"attention_mask\"].to(device)\n","    targets = d[\"targets\"].to(device)\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    _, preds = torch.max(outputs, dim=1)\n","    loss = loss_fn(outputs, targets)\n","\n","    correct_predictions += torch.sum(preds == targets)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)\n","\n","\n","def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"2pdyJMEcUfZu","executionInfo":{"status":"ok","timestamp":1668502255373,"user_tz":-480,"elapsed":4,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["# %%time\n","\n","# history = defaultdict(list)\n","# best_accuracy = 0\n","\n","# for epoch in range(EPOCHS):\n","\n","#   print(f'Epoch {epoch + 1}/{EPOCHS}')\n","#   print('-' * 10)\n","\n","#   train_acc, train_loss = train_epoch(\n","#     model,\n","#     train_data_loader,    \n","#     loss_fn, \n","#     optimizer, \n","#     device, \n","#     scheduler, \n","#     len(df_train)\n","#   )\n","\n","#   print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","#   val_acc, val_loss = eval_model(\n","#     model,\n","#     val_data_loader,\n","#     loss_fn, \n","#     device, \n","#     len(df_val)\n","#   )\n","\n","#   print(f'Val   loss {val_loss} accuracy {val_acc}')\n","#   print()\n","\n","#   history['train_acc'].append(train_acc)\n","#   history['train_loss'].append(train_loss)\n","#   history['val_acc'].append(val_acc)\n","#   history['val_loss'].append(val_loss)\n","\n","#   if val_acc > best_accuracy:\n","#     torch.save(model.state_dict(), 'best_model_state.bin')\n","#     best_accuracy = val_acc"],"metadata":{"id":"ed7xaTafXLPq","executionInfo":{"status":"ok","timestamp":1668502255374,"user_tz":-480,"elapsed":5,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["# plt.plot(history['train_acc'], label='train accuracy')\n","# plt.plot(history['val_acc'], label='validation accuracy')\n","\n","# plt.title('Training history')\n","# plt.ylabel('Accuracy')\n","# plt.xlabel('Epoch')\n","# plt.legend()\n","# plt.ylim([0, 1]);"],"metadata":{"id":"61bU-B6aXUEE","executionInfo":{"status":"ok","timestamp":1668502255374,"user_tz":-480,"elapsed":4,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"GUlLvFCmJX3h"}},{"cell_type":"code","source":["model = SentimentClassifier(len(class_names))\n","model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","model.eval()\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vd_9m18Ja9Y","executionInfo":{"status":"ok","timestamp":1668502262903,"user_tz":-480,"elapsed":7533,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"d9712bd2-31a2-411b-c643-c6f7d8c6dc0e"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"mH2zciPgXYmb"}},{"cell_type":"code","source":["test_acc, _ = eval_model(\n","  model,\n","  test_data_loader,\n","  loss_fn,\n","  device,\n","  len(df_test)\n",")\n","\n","test_acc.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsG2p-ZQXaDC","executionInfo":{"status":"ok","timestamp":1668502400893,"user_tz":-480,"elapsed":138007,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"3b62b0a7-cca5-4f88-a565-8e4125e471e5"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8677685950413223"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["def get_predictions(model, data_loader):\n","  model = model.eval()\n","  \n","  review_texts = []\n","  predictions = []\n","  prediction_probs = []\n","  real_values = []\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n"," \n","      texts = d[\"review_text\"]\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      probs = F.softmax(outputs, dim=1)\n","\n","      review_texts.extend(texts)\n","      predictions.extend(preds)\n","      prediction_probs.extend(probs)\n","      real_values.extend(targets)\n","\n","  if predictions: predictions = torch.stack(predictions)\n","  else: predictions = torch.tensor([])\n","\n","  if prediction_probs: prediction_probs = torch.stack(prediction_probs)\n","  else: prediction_probs = torch.tensor([])\n","\n","  if real_values: real_values = torch.stack(real_values)\n","  else: real_values = torch.tensor([])\n","\n","\n","  # predictions = torch.stack(predictions).cpu()\n","  # prediction_probs = torch.stack(prediction_probs).cpu()\n","  # real_values = torch.stack(real_values).cpu()\n","  return review_texts, predictions, prediction_probs, real_values"],"metadata":{"id":"I1zKYudAWtXb","executionInfo":{"status":"ok","timestamp":1668502400894,"user_tz":-480,"elapsed":25,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n","  model,\n","  test_data_loader\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBpGPvIgWvEq","executionInfo":{"status":"ok","timestamp":1668502523894,"user_tz":-480,"elapsed":123022,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"4e1e099b-65f0-4e2b-d934-918ae1db145b"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"]}]},{"cell_type":"code","source":["y_review_texts[3]\n","# y_pred_probs[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"Qa4S_9oWjAFF","executionInfo":{"status":"ok","timestamp":1668502523895,"user_tz":-480,"elapsed":39,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"25260b61-3960-4ad0-91e8-b108732fe129"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Our in-depth expertise extends to the fields of energy , industry , urban & mobility and water & environment .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred, target_names=class_names))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRNTJwkMWxUR","executionInfo":{"status":"ok","timestamp":1668502523895,"user_tz":-480,"elapsed":34,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"f7bf028b-d7dd-46ee-e7f0-5272fb437078"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","    negative       0.85      0.88      0.87        33\n","     neutral       0.87      0.93      0.90       134\n","    positive       0.86      0.76      0.81        75\n","\n","    accuracy                           0.87       242\n","   macro avg       0.86      0.85      0.86       242\n","weighted avg       0.87      0.87      0.87       242\n","\n"]}]},{"cell_type":"code","source":["def show_confusion_matrix(confusion_matrix):\n","  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n","  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n","  plt.ylabel('True sentiment')\n","  plt.xlabel('Predicted sentiment');\n","\n","cm = confusion_matrix(y_test, y_pred)\n","df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n","show_confusion_matrix(df_cm)"],"metadata":{"id":"RAf-HsoigeTF","executionInfo":{"status":"ok","timestamp":1668502523895,"user_tz":-480,"elapsed":29,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":["## Samples"],"metadata":{"id":"8fIje8SbXT71"}},{"cell_type":"code","source":["idx = 2\n","\n","review_text = y_review_texts[idx]\n","true_sentiment = y_test[idx]\n","pred_df = pd.DataFrame({\n","  'class_names': class_names,\n","  'values': y_pred_probs[idx]\n","})"],"metadata":{"id":"kRUBefzdghQW","executionInfo":{"status":"ok","timestamp":1668502523895,"user_tz":-480,"elapsed":28,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["print(\"\\n\".join(wrap(review_text)))\n","print()\n","print(f'True sentiment: {class_names[true_sentiment]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09AX9Jnwgi_o","executionInfo":{"status":"ok","timestamp":1668502523896,"user_tz":-480,"elapsed":29,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"0f33ec0e-8daa-419b-e298-cd7f71ca63ca"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["( ADP News ) - Nov 5 , 2008 - Finnish electronic measurement products\n","and solutions maker Vaisala Oyj ( OMX : VAIAS ) said today that its\n","net profit rose to EUR 18 million ( USD 23.1 m ) for the first nine\n","months of 2008 from EUR 1\n","\n","True sentiment: positive\n"]}]},{"cell_type":"code","source":["sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n","plt.ylabel('sentiment')\n","plt.xlabel('probability')\n","plt.xlim([0, 1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaXql169g0ws","executionInfo":{"status":"ok","timestamp":1668502523896,"user_tz":-480,"elapsed":27,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"dbf1d825-61fc-4ff1-a749-49060b4b65b4"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.0, 1.0)"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["pred_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"9GhTC8UeYQ1L","executionInfo":{"status":"ok","timestamp":1668502523896,"user_tz":-480,"elapsed":25,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"d70ea19f-6118-4b6f-e465-1fcbba939d8b"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  class_names    values\n","0  negative    0.020700\n","1  neutral     0.048426\n","2  positive    0.930874"],"text/html":["\n","  <div id=\"df-6a2ef039-526a-4a9d-9c03-0137b6ec1ca8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class_names</th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>negative</td>\n","      <td>0.020700</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>neutral</td>\n","      <td>0.048426</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>positive</td>\n","      <td>0.930874</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a2ef039-526a-4a9d-9c03-0137b6ec1ca8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6a2ef039-526a-4a9d-9c03-0137b6ec1ca8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6a2ef039-526a-4a9d-9c03-0137b6ec1ca8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["review_text = \"FB EPS dropped by 5% \""],"metadata":{"id":"WLDoIlgUg3aY","executionInfo":{"status":"ok","timestamp":1668502523896,"user_tz":-480,"elapsed":24,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["encoded_review = tokenizer.encode_plus(\n","  review_text,\n","  max_length=MAX_LEN,\n","  add_special_tokens=True,\n","  return_token_type_ids=False,\n","  pad_to_max_length=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',\n",")\n","\n","input_ids = encoded_review['input_ids'].to(device)\n","attention_mask = encoded_review['attention_mask'].to(device)\n","\n","output = model(input_ids, attention_mask)\n","_, prediction = torch.max(output, dim=1)\n","\n","print(f'Review text: {review_text}')\n","print(f'Sentiment  : {class_names[prediction]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rA0VcYJ9g4dB","executionInfo":{"status":"ok","timestamp":1668502523898,"user_tz":-480,"elapsed":26,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"9ea9b3b7-67db-4c6f-a27c-ad79ae054a93"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"]},{"output_type":"stream","name":"stdout","text":["Review text: FB EPS dropped by 5% \n","Sentiment  : negative\n"]}]},{"cell_type":"markdown","source":["## on actual data"],"metadata":{"id":"SYk7ueC3cwuT"}},{"cell_type":"code","source":["spy=ffn.get('spy', start='2021-01-01',  end='2021-12-01') # get spy prices from 01.01.2018\n","spy['date'] = spy.index.astype(str) # convert date to string \n","sent_vals = []\n","spy.plot(figsize=(10, 5));"],"metadata":{"id":"LaUeny2UXZY6","executionInfo":{"status":"ok","timestamp":1668502523898,"user_tz":-480,"elapsed":24,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["with open (colab_path + 'data/comments.pickle', 'rb') as fp:\n","    comments = pickle.load(fp)\n","\n","with open (colab_path + 'data/daily_comments.pickle', 'rb') as fp:\n","    daily_comments = pickle.load(fp)\n","\n","#daily_comments list of comment list\n","posts = pd.read_pickle(colab_path + 'data/posts.pickle')"],"metadata":{"id":"TtZxRLUEYHEV","executionInfo":{"status":"ok","timestamp":1668502523899,"user_tz":-480,"elapsed":24,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["comments[0]\n","posts.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"JEqzdSaPYW7p","executionInfo":{"status":"ok","timestamp":1668502523899,"user_tz":-480,"elapsed":24,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"outputId":"2abf3386-1600-43c3-822d-e41c9b50a45a"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       id                                         title  \\\n","0  ko9i5u  Daily Discussion Thread for January 01, 2021   \n","\n","                                                                                                    url  \\\n","0  https://www.reddit.com/r/wallstreetbets/comments/ko9i5u/daily_discussion_thread_for_january_01_2021/   \n","\n","         date             flair  sentiment score  \n","0  2021-01-01  Daily Discussion  43.238           "],"text/html":["\n","  <div id=\"df-b566db8b-2c3c-4c4e-b8d7-bb79acf68eea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>url</th>\n","      <th>date</th>\n","      <th>flair</th>\n","      <th>sentiment score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ko9i5u</td>\n","      <td>Daily Discussion Thread for January 01, 2021</td>\n","      <td>https://www.reddit.com/r/wallstreetbets/comments/ko9i5u/daily_discussion_thread_for_january_01_2021/</td>\n","      <td>2021-01-01</td>\n","      <td>Daily Discussion</td>\n","      <td>43.238</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b566db8b-2c3c-4c4e-b8d7-bb79acf68eea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b566db8b-2c3c-4c4e-b8d7-bb79acf68eea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b566db8b-2c3c-4c4e-b8d7-bb79acf68eea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["def loader(data):\n","  pd_comments = pd.DataFrame(data, columns=[\"sentence\"])\n","  pd_comments['label'] = 0\n","# pd_comments.head()\n","  comments_load = create_data_loader(pd_comments, tokenizer, MAX_LEN, BATCH_SIZE)\n","  \n","  return comments_load\n","  \n","comments_load = loader(comments)"],"metadata":{"id":"mervBGlAgcZ0","executionInfo":{"status":"ok","timestamp":1668502523899,"user_tz":-480,"elapsed":23,"user":{"displayName":"Galen Hew","userId":"14593423718388120675"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"36aaa6b3-2bee-4741-83c0-ba7a1952c574"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]}]},{"cell_type":"code","source":["review_texts, pred, pred_probs, test = get_predictions(\n","  model,\n","  comments_load\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gr3j7H7Fheri","outputId":"1f21c630-f16a-465d-e754-ee1dc71a0c4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"]}]},{"cell_type":"code","source":["statistics.mean(pred.tolist())"],"metadata":{"id":"bt0cmxNWrf70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # comment out after obtaining score 'sentiment-score-2' in pickle\n","\n","# scores=[] # list that will hold scores\n","# for comments in tqdm.tqdm(daily_comments): # iterate over comments by day, a list that holds lists\n","#   sentiment_score=0\n","#   comments_load = loader(comments)\n","#   review_texts, pred, pred_probs, test = get_predictions(\n","#     model,\n","#     comments_load\n","#   )\n","#   try:\n","#     for comment in comments: # iterate over every comment of every day\n","#       sentiment_score=sentiment_score+ statistics.mean(pred.tolist())\n","#     scores.append(sentiment_score) # append to scores list\n","#   except TypeError: #when error occurs\n","#     sentiment_score=0 # set score to zero for the day\n","#     scores.append(sentiment_score) # append score to the scores list\n","    \n","# posts['sentiment-score-2']=scores"],"metadata":{"id":"HJnuyoFxoVnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# posts.to_pickle(colab_path + 'data/posts2.pickle')"],"metadata":{"id":"INjdwBcj0JHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["posts.head(2)"],"metadata":{"id":"B24A8z6Y7ujY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["posts['date'] = pd.to_datetime(posts['date'])\n","posts= posts.sort_values(by=\"date\")\n","posts['date']= posts['date'].dt.strftime('%Y-%m-%d')"],"metadata":{"id":"E8V0l8DG8P0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["post_mean = posts['sentiment-score-2'].mean()\n","post_mean"],"metadata":{"id":"VlYJArmzA5pS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# replace outliers with mean, since need data everyday\n","\n","posts['sentiment-score-2'] = np.where(posts['sentiment-score-2']< 400, post_mean, posts['sentiment-score-2'])"],"metadata":{"id":"NbpyFMRsAjHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["posts[['sentiment-score-2', 'sentiment score']].plot()"],"metadata":{"id":"qGkHGy5R7QiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spy_senti = spy.merge(posts, how=\"inner\", on=\"date\")\n","spy_senti.head(3)"],"metadata":{"id":"e1FFbejK-io3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spy_senti[['sentiment-score-2', 'spy']].plot(secondary_y='sentiment-score-2')"],"metadata":{"id":"hmdG9usgBhiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# extract sentiment score as a discrete fourier transform\n","price_fourier = np.fft.fft(np.asarray(spy_senti['sentiment-score-2'].tolist())) # convert sentiment to FFT with numpy\n","fourier_df = pd.DataFrame({'fourier':price_fourier}) # add to a dataframe\n","fourier_list = np.asarray(fourier_df['fourier'].tolist())  # extract fourier score as array\n","\n","for num_ in range(5,30,5): # create fourier columns with scores 20 and 25\n","  # compound fourier to smoothen signal\n","  fourier_list_m10= np.copy(fourier_list)\n","  fourier_list_m10[num_:-num_]=0 \n","  # transform back into time spectrum append each fourier to dataframe with name of fourier\n","  spy_senti['fourier '+str(num_)]=np.fft.ifft(fourier_list_m10)\n","    \n","# # plotting sentiment score and fourier transformed scores with different compounds\n","spy_senti[['sentiment-score-2', 'fourier 5', 'fourier 10', 'fourier 15', 'fourier 20', 'fourier 25']].plot(figsize=(20, 10))\n"],"metadata":{"id":"sfQ4n3UZB-6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spy_senti = spy_senti.drop(['fourier 5', 'fourier 10', 'fourier 15', 'fourier 20'], axis = 1)"],"metadata":{"id":"cKmjD0ccCG5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert fourier to real\n","spy_senti['sent_smooth'] = spy_senti['fourier 25'].apply(lambda x: np.real(x))\n","spy_senti[['sent_smooth', 'sentiment-score-2']].plot(secondary_y='sent_smooth',figsize=(10, 5))"],"metadata":{"id":"RWCFcdonCH1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spy_senti.dtypes"],"metadata":{"id":"AOj227jICST3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spy_senti[['sent_smooth', 'spy']].plot(secondary_y='sent_smooth')"],"metadata":{"id":"GHVoISqFCXoh"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}